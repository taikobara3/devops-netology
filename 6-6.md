# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

В mongodb должны быть включены средства профилирования 

```
db.setProfilingLevel(2)
или
db.setProfilingLevel(1)
```

В последнем случае необходимо определить уровень "медленности" запросов: 

```
db.setProfilingLevel(1, 1000)
```

где 1000 - количество миллисекунд, после которых запрос будет считаться медленным
Далее находим операции, продолжающиеся более 3 минут:

```
db.currentOp({"secs_running":{$gte: 180}})
```

Убить нужный запрос командой:

```
db.killOp(opid)
```

Для решения проблем с долгими запросами в mongodb:
Указанным выше запросом найти долгие запросы
Просомтреть план выполнения этих запросов:

```
explain(‘executionStats’)
```

Наиболее вероятная причина медленного выполнения запросов - проблемы с индексацией. Попробовать создать/пересоздать индекс

## Задача 2

Несколько непонятно сформулировано условие задачи.

Если отношение количества записанных ключей к истекшим - величина постоянная, и УВЕЛИЧИВАЕТСЯ пропорционально количеству реплик, то ситуация, когда при масштабировании сервиса отношение количества записанных ключей к истекшим становится больше - собственно и описывается этим условием.

Увидели, то, что ожидали. Тавтология какая-то...

Впрочем, при использовании активного способа удаления истекших ключей, при росте количества записанных - может наступить момент, когда истекших ключей станет больше 25%, и алгоритм зациклится, что вызовет временную блокировку записи.

Можно попробовать увеличить значение параметра ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP на некоторую разумную величину, чтобы избежать зацикливания.

Кроме того, рост относительного количества записанных значений key-value к количеству истекших должен приводить к росту БД

Поскольку БД находится в оперативной памяти - предполагаю, что размер ее мог превысить ресурсы, доступные на сервере, поэтому и может возникать блокировка на запись

Также необходимо исключить проблемы сетевой связанности между узлами кластера.

## Задача 3

Скорее всего данная ошибка происходит при запросе на выборку очень большого количества данных и/или неоптимальной настройке индексов
Возможные пути решения:
* Проанализировать планы длительных запросов, оптимизировать их по возможности, при необходимости добавить или перестроить индексы
* Если проблема продолжает оставаться - увеличить значение параметра net_read_timeout
* При возможности - улучшить параметры сервера (кластера) - объем оперативной памяти, быстродействие дисковой подсистемы
* Увеличить значения параметров interactive_timeout, connect_timeout, wait_timeout
* Увеличить значение параметра max_connections

## Задача 4

oom-killer убивает процессы, потребляющие значительное количество оперативной памяти для предотвращения краха системы из-за отсутствия свободной памяти
Для решения данной проблемы можно:
* Увеличить объем оперативной памяти на сервере
* Ограничить объем оперативной памяти, доступной PG (может привести к критичному замедлению работы СУБД). Например снизить объемы shared_buffer, effective_cache_size, work_mem. Проверить ориентировочно их настройки, например, здесь: по https://pgtune.leopard.in.ua/
* Попробовать перенастроить запросы, приводящие к повышенному потреблению памяти (напр. выгружать данные batch меньшего размера)
* Попробовать настроить oom-killer: например, при помощи параметра oomprotect команды rcctl; или запретом реального выделения зарезервированной памячти (ограничением размера) - параметр overcommit_ratio, переменная vm.overcommit_memory
